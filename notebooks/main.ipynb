{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import mysql.connector\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARK Invest API base url\n",
    "base_url = 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/'\n",
    "\n",
    "# ARK Invest ETF names\n",
    "funds = ['ARK_INNOVATION_ETF_ARKK_HOLDINGS',\n",
    "'ARK_NEXT_GENERATION_INTERNET_ETF_ARKW_HOLDINGS',\n",
    "'ARK_FINTECH_INNOVATION_ETF_ARKF_HOLDINGS',\n",
    "'THE_3D_PRINTING_ETF_PRNT_HOLDINGS',\n",
    "'ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS',\n",
    "'ARK_AUTONOMOUS_TECH._&_ROBOTICS_ETF_ARKQ_HOLDINGS',\n",
    "'ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS',\n",
    "'ARK_ISRAEL_INNOVATIVE_TECHNOLOGY_ETF_IZRL_HOLDINGS']\n",
    "\n",
    "# Request headers\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df1 = df.copy()\n",
    "    df1.drop(df.index[-1], inplace=True) # drop last row\n",
    "    df1.fillna(0, inplace=True) # fill NaN with 0\n",
    "    df1.rename(columns={'market value ($)': 'market_value', 'weight (%)': 'weight'}, inplace=True) # rename columns\n",
    "    df1['date'] = pd.to_datetime(df1['date'], format=\"%m/%d/%Y\") # Convert the \"date\" column to datetime\n",
    "    df1['market_value'] = df1['market_value'].str.replace(r'[^\\d.]', '', regex=True).astype(float) # remove $ and , and convert to float\n",
    "    df1['shares'] = df1['shares'].str.replace(r'[^\\d.]', '', regex=True).astype(int) # remove , and convert to float\n",
    "    df1['weight'] = df1['weight'].str.replace(r'[^\\d.]', '', regex=True).astype(float) / 100 # remove % and convert to unitary float\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def insert_data_into_db(data_frame):\n",
    "    try:\n",
    "        db_config = {\n",
    "            \"host\": \"ark-digest.crubyqmjsrku.eu-west-3.rds.amazonaws.com\",\n",
    "            \"user\": os.getenv('DB_USER'),\n",
    "            \"password\": os.getenv('DB_PASS'),\n",
    "            \"database\": \"ark_digest\",\n",
    "        }\n",
    "\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        table_name = 'holdings' \n",
    "\n",
    "        for index, row in data_frame.iterrows():\n",
    "            try:\n",
    "                insert_query = f\"\"\"\n",
    "                    INSERT INTO {table_name} (date, fund, company, ticker, cusip, shares, market_value, weight)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "\n",
    "                data_tuple = (\n",
    "                    row['date'], row['fund'], row['company'], row['ticker'],\n",
    "                    row['cusip'], row['shares'], row['market_value'], row['weight']\n",
    "                )\n",
    "\n",
    "                cursor.execute(insert_query, data_tuple)\n",
    "                connection.commit()\n",
    "\n",
    "            except Error as e:\n",
    "                print(f\"Error inserting row {index}: {e}\")\n",
    "                connection.rollback()  # Rollback the transaction for the current row\n",
    "\n",
    "        print(\"Data insertion completed!\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n",
      "Data insertion completed!\n"
     ]
    }
   ],
   "source": [
    "for fund in funds:\n",
    "\n",
    "    url = f'{base_url}{fund}.csv'\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        csv_content = response.content.decode('utf-8')\n",
    "        df = pd.read_csv(StringIO(csv_content)) \n",
    "        df = clean_data(df)\n",
    "        insert_data_into_db(df)\n",
    "    else:\n",
    "        print(f\"Failed to download the CSV file. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
